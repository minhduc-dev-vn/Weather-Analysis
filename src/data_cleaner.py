# src/data_cleaner.py
"""
Module x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu th·ªùi ti·∫øt.

Ch·ª©c nƒÉng:
    - ƒê·ªçc d·ªØ li·ªáu th√¥ t·ª´ CSV
    - Ki·ªÉm tra v√† lo·∫°i b·ªè d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá
    - Chu·∫©n h√≥a ƒë·ªãnh d·∫°ng v√† t√™n c·ªôt
    - L√†m tr√≤n s·ªë li·ªáu
    - L∆∞u d·ªØ li·ªáu s·∫°ch th√†nh CSV

Author: Weather Forecast Pro Team
Date: 2025-12-27 (Refactored for code quality)
"""

import pandas as pd
import os
from typing import Optional, List

from .config import DEFAULT_CITY_VIET, get_raw_data_path, get_processed_data_path
from .constants import (
    MIN_VALID_TEMPERATURE, MAX_VALID_TEMPERATURE,
    MIN_VALID_HUMIDITY, MAX_VALID_HUMIDITY,
    MIN_VALID_WIND_SPEED,
    MISSING_VALUE_THRESHOLD,
    EMOJI_FILE, EMOJI_CHART
)
from .column_names import RawColumns, CleanColumns, rename_to_clean
from .exceptions import FileOperationError, DataValidationError, DataProcessingError, EmptyDataFrameError
from .logger import get_logger, log_success, log_error, log_warning, log_info


# Logger cho module n√†y
logger = get_logger(__name__)


def _validate_file_exists(filepath: str) -> None:
    """
    Ki·ªÉm tra file d·ªØ li·ªáu th√¥ t·ªìn t·∫°i.
    
    Args:
        filepath: ƒê∆∞·ªùng d·∫´n file c·∫ßn ki·ªÉm tra
        
    Raises:
        FileOperationError: N·∫øu file kh√¥ng t·ªìn t·∫°i
    """
    if not os.path.exists(filepath):
        error_msg = f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu th√¥: {filepath}. Vui l√≤ng ch·∫°y c·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ API tr∆∞·ªõc."
        log_error(error_msg, logger)
        raise FileOperationError(error_msg, filepath)


def _load_raw_data(filepath: str) -> pd.DataFrame:
    """
    ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV.
    
    Args:
        filepath: ƒê∆∞·ªùng d·∫´n file CSV
        
    Returns:
        pd.DataFrame: DataFrame ch·ª©a d·ªØ li·ªáu th√¥
        
    Raises:
        FileOperationError: N·∫øu kh√¥ng th·ªÉ ƒë·ªçc file
    """
    try:
        logger.info(f"ƒêang ƒë·ªçc file: {filepath}")
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        log_success(f"ƒê√£ ƒë·ªçc {len(df)} d√≤ng d·ªØ li·ªáu", logger)
        return df
        
    except pd.errors.ParserError as e:
        error_msg = f"L·ªói parse CSV: {e}"
        log_error(error_msg, logger, exc_info=True)
        raise FileOperationError(error_msg, filepath) from e
        
    except Exception as e:
        error_msg = f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi ƒë·ªçc file: {e}"
        log_error(error_msg, logger, exc_info=True)
        raise FileOperationError(error_msg, filepath) from e


def _validate_required_columns(df: pd.DataFrame) -> None:
    """
    Ki·ªÉm tra c√°c c·ªôt b·∫Øt bu·ªôc ph·∫£i c√≥.
    
    Args:
        df: DataFrame c·∫ßn ki·ªÉm tra
        
    Raises:
        DataValidationError: N·∫øu thi·∫øu c·ªôt b·∫Øt bu·ªôc
    """
    required_columns = [
        RawColumns.DT_TXT.value,
        RawColumns.TEMP.value,
        RawColumns.HUMIDITY.value,
        RawColumns.PRESSURE.value,
        RawColumns.WIND_SPEED.value,
        RawColumns.DESCRIPTION.value
    ]
    
    missing_cols = [col for col in required_columns if col not in df.columns]
    
    if missing_cols:
        error_msg = f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {missing_cols}. C√°c c·ªôt hi·ªán c√≥: {df.columns.tolist()}"
        log_error(error_msg, logger)
        raise DataValidationError(error_msg)
    
    log_success("T·∫•t c·∫£ c√°c c·ªôt b·∫Øt bu·ªôc ƒë·ªÅu c√≥ s·∫µn", logger)


def _handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:
    """
    X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu (missing values).
    
    Args:
        df: DataFrame c·∫ßn x·ª≠ l√Ω
        
    Returns:
        pd.DataFrame: DataFrame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω missing values
    """
    logger.info("Ki·ªÉm tra d·ªØ li·ªáu thi·∫øu...")
    missing_info = df.isnull().sum()
    
    if missing_info.sum() > 0:
        log_warning("Ph√°t hi·ªán d·ªØ li·ªáu thi·∫øu:", logger)
        for col, count in missing_info[missing_info > 0].items():
            logger.warning(f"  - {col}: {count} d√≤ng")
        
        # ƒêi·ªÅn gi√° tr·ªã cho c√°c c·ªôt c·ª• th·ªÉ
        if RawColumns.PRESSURE.value in df.columns:
            df[RawColumns.PRESSURE.value] = df[RawColumns.PRESSURE.value].fillna(
                df[RawColumns.PRESSURE.value].mean()
            )
        
        if RawColumns.WIND_SPEED.value in df.columns:
            df[RawColumns.WIND_SPEED.value] = df[RawColumns.WIND_SPEED.value].fillna(0)
        
        if RawColumns.DESCRIPTION.value in df.columns:
            df[RawColumns.DESCRIPTION.value] = df[RawColumns.DESCRIPTION.value].fillna('Kh√¥ng x√°c ƒë·ªãnh')
        
        # X·ª≠ l√Ω c√°c c·ªôt optional
        if RawColumns.FEELS_LIKE.value in df.columns:
            df[RawColumns.FEELS_LIKE.value] = df[RawColumns.FEELS_LIKE.value].fillna(
                df[RawColumns.TEMP.value]
            )
        
        if RawColumns.WIND_DEG.value in df.columns:
            df[RawColumns.WIND_DEG.value] = df[RawColumns.WIND_DEG.value].fillna(
                df[RawColumns.WIND_DEG.value].median()
            )
        
        if RawColumns.CLOUDS.value in df.columns:
            df[RawColumns.CLOUDS.value] = df[RawColumns.CLOUDS.value].fillna(
                df[RawColumns.CLOUDS.value].median()
            )
        
        if RawColumns.VISIBILITY.value in df.columns:
            df[RawColumns.VISIBILITY.value] = df[RawColumns.VISIBILITY.value].fillna(
                df[RawColumns.VISIBILITY.value].median()
            )
        
        log_success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu (ƒëi·ªÅn gi√° tr·ªã h·ª£p l√Ω)", logger)
    else:
        log_success("Kh√¥ng c√≥ d·ªØ li·ªáu thi·∫øu", logger)
    
    return df


def _remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
    """
    Lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p.
    
    Args:
        df: DataFrame c·∫ßn x·ª≠ l√Ω
        
    Returns:
        pd.DataFrame: DataFrame ƒë√£ lo·∫°i b·ªè duplicate
    """
    logger.info("Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p...")
    dup_before = len(df)
    df = df.drop_duplicates(subset=[RawColumns.DT_TXT.value], keep='first')
    dup_count = dup_before - len(df)
    
    if dup_count > 0:
        log_warning(f"Ph√°t hi·ªán {dup_count} d√≤ng tr√πng l·∫∑p (ƒë√£ lo·∫°i b·ªè)", logger)
    else:
        log_success("Kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p", logger)
    
    return df


def _convert_datetime_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    Chuy·ªÉn ƒë·ªïi c·ªôt th·ªùi gian sang DateTime.
    
    Args:
        df: DataFrame c·∫ßn x·ª≠ l√Ω
        
    Returns:
        pd.DataFrame: DataFrame v·ªõi c·ªôt th·ªùi gian ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi
        
    Raises:
        DataProcessingError: N·∫øu kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi
    """
    logger.info("Chuy·ªÉn ƒë·ªïi c·ªôt th·ªùi gian...")
    try:
        df[RawColumns.DT_TXT.value] = pd.to_datetime(df[RawColumns.DT_TXT.value])
        log_success("Chuy·ªÉn ƒë·ªïi th√†nh c√¥ng sang ƒë·ªãnh d·∫°ng DateTime", logger)
        return df
        
    except Exception as e:
        error_msg = f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi th·ªùi gian: {e}"
        log_error(error_msg, logger, exc_info=True)
        raise DataProcessingError(error_msg) from e


def _validate_data_ranges(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ki·ªÉm tra v√† lo·∫°i b·ªè gi√° tr·ªã ngo·∫°i l·ªá (outliers).
    
    Args:
        df: DataFrame c·∫ßn ki·ªÉm tra
        
    Returns:
        pd.DataFrame: DataFrame ƒë√£ lo·∫°i b·ªè outliers
    """
    logger.info("Ki·ªÉm tra gi√° tr·ªã ngo·∫°i l·ªá...")
    
    initial_len = len(df)
    
    # Ki·ªÉm tra nhi·ªát ƒë·ªô
    temp_col = RawColumns.TEMP.value
    invalid_temp = df[(df[temp_col] < MIN_VALID_TEMPERATURE) | (df[temp_col] > MAX_VALID_TEMPERATURE)]
    if len(invalid_temp) > 0:
        log_warning(f"T√¨m th·∫•y {len(invalid_temp)} gi√° tr·ªã nhi·ªát ƒë·ªô ngo·∫°i l·ªá (lo·∫°i b·ªè)", logger)
        df = df.drop(invalid_temp.index)
    
    # Ki·ªÉm tra ƒë·ªô ·∫©m
    humidity_col = RawColumns.HUMIDITY.value
    invalid_humidity = df[(df[humidity_col] < MIN_VALID_HUMIDITY) | (df[humidity_col] > MAX_VALID_HUMIDITY)]
    if len(invalid_humidity) > 0:
        log_warning(f"T√¨m th·∫•y {len(invalid_humidity)} gi√° tr·ªã ƒë·ªô ·∫©m ngo·∫°i l·ªá (lo·∫°i b·ªè)", logger)
        df = df.drop(invalid_humidity.index)
    
    # Ki·ªÉm tra t·ªëc gi√≥
    wind_col = RawColumns.WIND_SPEED.value
    invalid_wind = df[df[wind_col] < MIN_VALID_WIND_SPEED]
    if len(invalid_wind) > 0:
        log_warning(f"T√¨m th·∫•y {len(invalid_wind)} gi√° tr·ªã t·ªëc gi√≥ √¢m (lo·∫°i b·ªè)", logger)
        df = df.drop(invalid_wind.index)
    
    removed = initial_len - len(df)
    if removed == 0:
        log_success("T·∫•t c·∫£ gi√° tr·ªã ƒë·ªÅu h·ª£p l·ªá", logger)
    else:
        logger.info(f"ƒê√£ lo·∫°i b·ªè t·ªïng {removed} b·∫£n ghi ngo·∫°i l·ªá")
    
    return df


def _round_numeric_values(df: pd.DataFrame) -> pd.DataFrame:
    """
    L√†m tr√≤n c√°c gi√° tr·ªã s·ªë.
    
    Args:
        df: DataFrame c·∫ßn x·ª≠ l√Ω
        
    Returns:
        pd.DataFrame: DataFrame v·ªõi c√°c gi√° tr·ªã ƒë√£ ƒë∆∞·ª£c l√†m tr√≤n
    """
    logger.info("L√†m tr√≤n s·ªë li·ªáu...")
    
    # L√†m tr√≤n c√°c c·ªôt b·∫Øt bu·ªôc
    df[RawColumns.TEMP.value] = df[RawColumns.TEMP.value].round(1)
    df[RawColumns.HUMIDITY.value] = df[RawColumns.HUMIDITY.value].round(0).astype(int)
    df[RawColumns.PRESSURE.value] = df[RawColumns.PRESSURE.value].round(0).astype(int)
    df[RawColumns.WIND_SPEED.value] = df[RawColumns.WIND_SPEED.value].round(2)
    
    # L√†m tr√≤n c√°c c·ªôt optional n·∫øu c√≥
    if RawColumns.FEELS_LIKE.value in df.columns:
        df[RawColumns.FEELS_LIKE.value] = df[RawColumns.FEELS_LIKE.value].round(1)
    
    if RawColumns.WIND_DEG.value in df.columns:
        df[RawColumns.WIND_DEG.value] = df[RawColumns.WIND_DEG.value].round(0).astype(int)
    
    if RawColumns.CLOUDS.value in df.columns:
        df[RawColumns.CLOUDS.value] = df[RawColumns.CLOUDS.value].round(0).astype(int)
    
    if RawColumns.VISIBILITY.value in df.columns:
        df[RawColumns.VISIBILITY.value] = df[RawColumns.VISIBILITY.value].round(2)
    
    log_success("L√†m tr√≤n ho√†n t·∫•t", logger)
    return df


def _rename_columns_vietnamese(df: pd.DataFrame) -> pd.DataFrame:
    """
    ƒê·ªïi t√™n c·ªôt sang ti·∫øng Vi·ªát.
    
    Args:
        df: DataFrame c·∫ßn ƒë·ªïi t√™n c·ªôt
        
    Returns:
        pd.DataFrame: DataFrame v·ªõi t√™n c·ªôt ti·∫øng Vi·ªát
    """
    logger.info("ƒê·ªïi t√™n c·ªôt sang Ti·∫øng Vi·ªát...")
    
    # S·ª≠ d·ª•ng mapping function t·ª´ column_names
    rename_dict = rename_to_clean(df.columns.tolist())
    df = df.rename(columns=rename_dict)
    
    logger.info(f"T√™n c·ªôt m·ªõi: {df.columns.tolist()}")
    return df


def _save_processed_data(df: pd.DataFrame, filepath: str) -> None:
    """
    L∆∞u DataFrame ƒë√£ x·ª≠ l√Ω th√†nh file CSV.
    
    Args:
        df: DataFrame c·∫ßn l∆∞u
        filepath: ƒê∆∞·ªùng d·∫´n file output
        
    Raises:
        FileOperationError: N·∫øu kh√¥ng th·ªÉ l∆∞u file
    """
    logger.info("L∆∞u file d·ªØ li·ªáu s·∫°ch...")
    
    try:
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        file_size = df.memory_usage(deep=True).sum() / 1024
        log_success("ƒê√£ l∆∞u d·ªØ li·ªáu s·∫°ch", logger)
        logger.info(f"{EMOJI_FILE} V·ªã tr√≠: {filepath}")
        logger.info(f"{EMOJI_CHART} T·ªïng b·∫£n ghi: {len(df)}")
        logger.info(f"{EMOJI_CHART} K√≠ch th∆∞·ªõc: {file_size:.2f} KB")
        
    except PermissionError as e:
        error_msg = f"Kh√¥ng c√≥ quy·ªÅn ghi file: {filepath}"
        log_error(error_msg, logger, exc_info=True)
        raise FileOperationError(error_msg, filepath) from e
        
    except IOError as e:
        error_msg = f"L·ªói I/O khi l∆∞u file: {e}"
        log_error(error_msg, logger, exc_info=True)
        raise FileOperationError(error_msg, filepath) from e


def _log_data_statistics(df: pd.DataFrame) -> None:
    """
    Log th·ªëng k√™ d·ªØ li·ªáu.
    
    Args:
        df: DataFrame c·∫ßn th·ªëng k√™
    """
    logger.info("\nüìà Th·ªëng k√™ d·ªØ li·ªáu:")
    logger.info(f"{'Th·ªùi gian:':20} {df[CleanColumns.THOI_GIAN.value].min()} ‚Üí {df[CleanColumns.THOI_GIAN.value].max()}")
    logger.info(f"{'Nhi·ªát ƒë·ªô (¬∞C):':20} Min: {df[CleanColumns.NHIET_DO.value].min()}, Max: {df[CleanColumns.NHIET_DO.value].max()}")
    logger.info(f"{'ƒê·ªô ·∫©m (%):':20} Min: {df[CleanColumns.DO_AM.value].min()}, Max: {df[CleanColumns.DO_AM.value].max()}")
    logger.info(f"{'√Åp su·∫•t (hPa):':20} Min: {df[CleanColumns.AP_SUAT.value].min()}, Max: {df[CleanColumns.AP_SUAT.value].max()}")
    
    # Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
    logger.info("\nüìã M·∫´u d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu):")
    logger.info(f"\n{df.head(5).to_string(index=False)}")


def clean_data(city_name_viet: str = DEFAULT_CITY_VIET) -> Optional[pd.DataFrame]:
    """
    ƒê·ªçc, x·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu th·ªùi ti·∫øt.
    
    Quy tr√¨nh x·ª≠ l√Ω:
    1. Ki·ªÉm tra file d·ªØ li·ªáu th√¥ t·ªìn t·∫°i
    2. ƒê·ªçc file CSV
    3. Validate c√°c c·ªôt b·∫Øt bu·ªôc
    4. X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu
    5. Lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p
    6. Chuy·ªÉn ƒë·ªïi c·ªôt th·ªùi gian sang DateTime
    7. Ki·ªÉm tra v√† lo·∫°i b·ªè gi√° tr·ªã ngo·∫°i l·ªá
    8. L√†m tr√≤n s·ªë li·ªáu
    9. ƒê·ªïi t√™n c·ªôt sang Ti·∫øng Vi·ªát
    10. L∆∞u file s·∫°ch
    
    Args:
        city_name_viet: T√™n th√†nh ph·ªë ti·∫øng Vi·ªát (m·∫∑c ƒë·ªãnh: "H√† N·ªôi")
    
    Returns:
        Optional[pd.DataFrame]: DataFrame ƒë√£ x·ª≠ l√Ω n·∫øu th√†nh c√¥ng,
                                None n·∫øu th·∫•t b·∫°i
                                
    Raises:
        FileOperationError: L·ªói file operations
        DataValidationError: D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá
        DataProcessingError: L·ªói x·ª≠ l√Ω d·ªØ li·ªáu
        EmptyDataFrameError: DataFrame r·ªóng
        
    Examples:
        >>> df = clean_data("H√† N·ªôi")
        >>> print(df.columns.tolist())
        ['Th·ªùi Gian', 'Nhi·ªát ƒê·ªô', 'Nhi·ªát ƒê·ªô C·∫£m Nh·∫≠n', 'ƒê·ªô ·∫®m', ...]
    """
    
    raw_data_path = get_raw_data_path(city_name_viet)
    processed_data_path = get_processed_data_path(city_name_viet)
    
    logger.info(f"üßπ B·∫Øt ƒë·∫ßu l√†m s·∫°ch d·ªØ li·ªáu cho: {city_name_viet}")
    
    try:
        # 1. Validate file t·ªìn t·∫°i
        _validate_file_exists(raw_data_path)
        
        # 2. ƒê·ªçc d·ªØ li·ªáu
        df = _load_raw_data(raw_data_path)
        
        # 3. Validate c·ªôt b·∫Øt bu·ªôc
        _validate_required_columns(df)
        
        # 4. X·ª≠ l√Ω missing values
        df = _handle_missing_values(df)
        
        # 5. Lo·∫°i b·ªè duplicate
        df = _remove_duplicates(df)
        
        # 6. Chuy·ªÉn ƒë·ªïi datetime
        df = _convert_datetime_column(df)
        
        # 7. Validate ranges v√† lo·∫°i b·ªè outliers
        df = _validate_data_ranges(df)
        
        # 8. Ki·ªÉm tra DataFrame kh√¥ng r·ªóng
        if len(df) == 0:
            error_msg = "T·∫•t c·∫£ d·ªØ li·ªáu ƒë√£ b·ªã lo·∫°i b·ªè sau khi clean!"
            log_error(error_msg, logger)
            raise EmptyDataFrameError(error_msg)
        
        # 9. L√†m tr√≤n s·ªë li·ªáu
        df = _round_numeric_values(df)
        
        # 10. ƒê·ªïi t√™n c·ªôt sang ti·∫øng Vi·ªát
        df = _rename_columns_vietnamese(df)
        
        # 11. L∆∞u file
        _save_processed_data(df, processed_data_path)
        
        # 12. Log statistics
        _log_data_statistics(df)
        
        return df
        
    except (FileOperationError, DataValidationError, DataProcessingError, EmptyDataFrameError) as e:
        logger.error(f"L·ªói khi clean data: {e}")
        return None
        
    except Exception as e:
        log_error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {type(e).__name__}: {e}", logger, exc_info=True)
        return None


if __name__ == "__main__":
    # Test code
    df = clean_data("H√† N·ªôi")
    if df is not None:
        logger.info("‚úÖ Test th√†nh c√¥ng!")